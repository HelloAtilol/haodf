#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Time    : 2018/8/10 18:54
# @FileName: advisory_page_down.py
# @Function: æ ¹æ®è¾“å…¥çš„èµ·æ­¢æ—¶é—´ï¼Œä¸‹è½½è¯¥æ—¶æ®µå†…å¥½å¤§å¤«åŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µï¼Œå¯è‡ªå®šä¹‰å…¨å±€å¸¸é‡ 2018-09-12 0234ï¼ˆæ–­ç‚¹ç»­çˆ¬ï¼‰

import datetime
import os
import time

import re
from selenium import webdriver
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.wait import WebDriverWait

# å®šä¹‰æŠ“å–æ•°æ®çš„urlï¼Œæ—¶é—´è·¨åº¦åŠå­˜å‚¨è·¯å¾„ç­‰åˆå§‹å€¼
BASE_URL = 'https://www.haodf.com/sitemap-zx/'
DATE_START = '20080222'
DATE_END = '20080223'
DIR_PATH = './'
TIME_WAIT = 30
TIME_SLEEP = 2
# log ç¼–ç æ–¹å¼
ENCODING_STYLE = 'gb18030'
# status
# æ–­ç‚¹å‘ç”Ÿæ—¥ï¼Œé»˜è®¤ä¸ºçˆ¬è™«èµ·å§‹é¡µ
CURRENT_DATE = DATE_START
# æ–­ç‚¹å‘ç”Ÿæ—¶æ­£åœ¨çˆ¬å–çš„æ—¥æœŸé¡µä¸ºç¬¬å‡ é¡µï¼Œé»˜è®¤ä¸º1
CURRENT_PAGE = 1
# æ–­ç‚¹å‘ç”Ÿæ—¶ list ä¸‹æ ‡ current_index æ­£å¥½ç­‰äºå·²æˆåŠŸçˆ¬å–çš„æ¡æ•°ï¼Œé»˜è®¤ä¸º0
current_index = 0

# chrome æ— çª—æ¨¡å¼
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
browser = webdriver.Chrome(chrome_options=chrome_options)

# æ˜¾å¼ç­‰å¾…
wait = WebDriverWait(browser, TIME_WAIT)


def down_detail_page(file_path, local_time):
    """
    æ„é€ æ—¥æœŸå¾ªç¯ï¼Œè°ƒç”¨creat_date_page_urlå‡½æ•°ï¼Œä¸‹è½½åŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µåˆ°æœ¬åœ°
    :param file_path:
    :param local_time:
    :return: 
    """
    # æŠ“å–ç½‘é¡µçš„èµ·æ­¢æ—¶é—´çš„å­—ç¬¦ä¸²å‹æ—¶é—´æ ¼å¼åŒ–ä¸ºæ—¥æœŸå‹
    advisory_date = datetime.datetime.strptime(DATE_START, '%Y%m%d')
    # æ–­ç‚¹å‘ç”Ÿæ—¥
    current_date = datetime.datetime.strptime(CURRENT_DATE, '%Y%m%d')
    advisory_date_end = datetime.datetime.strptime(DATE_END, '%Y%m%d')
    # æ˜¯å¦æ–­ç‚¹ç»­çˆ¬
    if advisory_date < current_date:
        advisory_date = current_date
    # else:
        # print('ä»åˆå§‹æ—¥æœŸ DATE_START å¼€å§‹çˆ¬å–ã€‚')
    # è·å–æ–­ç‚¹é¡µé¡µç ï¼Œé¦–æ¬¡çˆ¬å–é¡µé¢æ•°ä¸€èˆ¬æ˜¯ CURRENT_PAGEï¼Œè¿™é‡Œä¸ºäº†é˜²æ­¢è¾“å…¥é¡µç å°äº1
    current_page = max(CURRENT_PAGE, 1)
    # éå†å¾…æŠ“å–ç½‘é¡µèµ·æ­¢æ—¶é—´åŒºé—´
    while advisory_date <= advisory_date_end:
        # ä¸‹é¢è°ƒç”¨å‡½æ•°ç”Ÿæˆå…¨éƒ¨æ¯æ—¥æ‰€æœ‰é¡µé¢çš„  URL ï¼Œè§£æå‡ºåŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µçš„ URL
        # è¯¥å‡½æ•°å†…éƒ¨è°ƒç”¨è·å–è¯¦æƒ…é¡µæºç çš„å‡½æ•° get_detail_page
        # =====================
        # é¦–å…ˆè€ƒè™‘ç”Ÿæˆæ—¶é—´æˆ³ï¼Œç„¶åå–å‰åä¸¤æ¬¡çš„å·®ï¼Œå¦‚æœå·®å°äºæŸä¸ªå€¼ï¼Œè¯´æ˜å¯èƒ½å­˜åœ¨æ‹’ç»è®¿é—®ã€
        # ç½‘é€Ÿå·®æˆ–å…¶ä»–æœªçŸ¥é”™è¯¯ï¼ŒæŠ“å–é¡µé¢ä¸æ­£å¸¸ï¼Œä½†ç¨‹åºä»åœ¨æ— æ•ˆè¿è¡Œï¼Œå¯èƒ½å‡ºç°åœ¨æŠ“å–æ—¥æœŸé¡µè¿‡ç¨‹ä¸­
        # =====================
        start_time = time.perf_counter()
        print(advisory_date)
        # è°ƒç”¨å‡½æ•°ç”ŸæˆæŸä¸€å¤©çš„æ¯ä¸€é¡µé¡µé¢ urlï¼Œç„¶åè§£æè·å–è¯¥é¡µé¢ä¸­çš„ title å’Œ url
        # creat_date_page_url(advisory_date, file_path, local_time, current_page)
        # åé¢çš„æ¯ä¸€å¤©éƒ½ä»ç¬¬ä¸€é¡µå¼€å§‹çˆ¬å–
        current_page = 1
        # è¾“å‡ºæµ®ç‚¹å‹æ•°æ®
        delta_time = time.perf_counter() - start_time
        # è¿™é‡Œè®¾ç½®å®ŒæˆæŸå¤©æŠ“å–å°äºå¤šå°‘æ—¶é—´æˆ–å¤§äºå¤šå°‘æ—¶é—´æ„ä¹‰ä¸å¤§ï¼Œå¯ä»¥å°†æ—¶å·®æ‰“å°å‡ºæ¥ï¼Œäººå·¥æ¥åˆ¤æ–­æ‰‹å·¥ç»ˆæ­¢ç¨‹åº
        # æš‚æ—¶ä¸æ¸…æ¥š browser.get()ä¼šä¸ä¼šè§¦å‘å¼‚å¸¸
        # ä»¥ä¸‹æœ¬æ¥åœ¨ä¸€è¡Œï¼Œdelta_time æœ‰ warning
        print(advisory_date.strftime('%Y-%m-%d'), ' æ—¥çš„é¡µé¢ç”¨æ—¶  ', end='')
        print(delta_time, end='')
        print('  ç§’è§£æå¹¶æŠ“å–å®Œæ¯•')
        # æ—¥æœŸæ¨è¿›ä¸€å¤©ï¼Œè”ç³»ä¸‹æ–‡ä¸ç”¨åŠ  time.sleep
        advisory_date += datetime.timedelta(days=1)
    else:
        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), ' ç¨‹åºé¡ºåˆ©è¿è¡Œç»“æŸ!')


def creat_date_page_url(advisory_date, file_path, local_time, current_page):
    """
    æ ¹æ®ä¼ å…¥çš„æ—¥æœŸå‚æ•°ï¼Œç”Ÿæˆè¯¥æ—¥æ‰€æœ‰é¡µé¢çš„ URL
    ç„¶åè§£æè¯¥é¡µé¢è·å–åŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µ URLï¼Œç„¶åè°ƒç”¨ get_detail_page ä¿å­˜è¯¦æƒ…é¡µ
    :param current_page:
    :param local_time:
    :param file_path:
    :param advisory_date:
    :return:
    """
    for date_page in range(current_page, 1000):
        date_page_url = BASE_URL + advisory_date.strftime('%Y%m%d') + '_' + str(date_page) + '/'
        # æ‰“å°çŠ¶æ€
        print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), ' å¼€å§‹å°è¯•æŠ“å– ', advisory_date.strftime('%Y-%m-%d'),
              ' æ—¥ç¬¬ ', str(date_page), ' é¡µé—®è¯Šè®°å½•')
        try:
            # è·å–å« title å’Œ detail page urlçš„é¡µé¢
            browser.get(date_page_url)
            # ç­‰é¡µé¢åŠ è½½æˆåŠŸç›´åˆ°æ—¶é—´è¶…è¿‡ TIME_WAIT
            wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class="map_all"]')))
            # æŸ¥æ‰¾é¡µé¢class nameä¸º'hh'çš„èŠ‚ç‚¹ã€‚è¿™é‡Œä¹Ÿå¯ä»¥ç”¨ try except åš
            # åˆ¤æ–­å¦‚æœæœ‰ hh å­˜åœ¨ï¼Œå¯¹è¯è¯¦æƒ…é¡µ title å’Œ url ä¸€å®šå­˜åœ¨ï¼Œè‡³å°‘ä¸º1ä¸ª
            browser.find_element_by_xpath('//li[@class="hh"]')
            # å’Œ html.xpath è·å– text()ä¸åŒã€‚ç”¨ elements
            item = browser.find_elements_by_xpath('//li/a')
            # å–è¯¦æƒ…é¡µæ•°é‡
            len_item = len(item)
            # å°† item çš„å±æ€§å€¼å³ title å’Œ url å­˜å…¥äºŒç»´æ•°ç»„ä¸­ï¼Œè°ƒç”¨å‡½æ•°creat_arr_title_urlï¼ˆï¼‰
            arr_title_url = creat_arr_title_url(item, len_item)
            # ç”Ÿæˆæœ€åç½‘é¡µæ–‡ä»¶åç§°å‰ç¼€
            pre_file_name = advisory_date.strftime('%Y%m%d') + '_' + str(date_page) + '_'
            # åˆ¤æ–­æ˜¯å¦ä»æŸé¡µéç¬¬ä¸€æ¡ url å¼€å§‹çˆ¬å–ï¼Œå¹¶é€šè¿‡ä¿®æ”¹å…¨å±€å˜é‡ç¡®ä¿åªæ‰§è¡Œä¸€æ¬¡
            global current_index
            start_index = 0
            if current_index:
                start_index = current_index
                current_index = 0
            for i in range(start_index, len_item):
                # æ‰“å°çŠ¶æ€
                print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), advisory_date.strftime('%Y-%m-%d'),
                      ' æ—¥ç¬¬ ', str(date_page), ' é¡µé—®è¯Šåˆ—è¡¨å…±æœ‰ ', str(len_item), ' æ¡é—®è¯Šé¡µåœ°å€ï¼Œæ­£åœ¨æŠ“å–ç¬¬ ', str(i+1), ' æ¡')
                # è®°å½•æ‰€æœ‰æˆåŠŸåŠ è½½çš„æŸæ—¥æŸé¡µé¢ä¸­æ‰€æœ‰çš„ title å’Œ urlï¼ŒåŒ…å«å¯èƒ½å°†æ²¡æœ‰æˆåŠŸä¿å­˜è‡³æœ¬åœ°çš„
                record_title_url_filename = 'TitleandUrl' + DATE_START + DATE_END + local_time
                with open(file_path + 'log/' + record_title_url_filename + '.txt', 'a', encoding=ENCODING_STYLE) \
                        as record_title_url:
                    record_title_url.write(arr_title_url[i][0] + '\t' + arr_title_url[i][1] + '\n')
                # è°ƒç”¨å‡½æ•°è·å–æŸä¸€æ—¥æŸä¸€é¡µä¸Šæ‰€æœ‰åŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µ URL å¯¹åº”çš„é¡µé¢å¹¶å­˜å…¥æœ¬åœ°
                get_detail_page(arr_title_url[i][0], pre_file_name, file_path, local_time)
                # è®°å½•æˆåŠŸçˆ¬å–çš„æœ€åä¸€ä¸ª url çš„çŠ¶æ€ï¼Œæ–­ç‚¹æ—¶æ­£åœ¨çˆ¬å–çš„ä¸ºè¿™é‡Œçš„ä¸‹ä¸€æ¡
                # å¯èƒ½å­˜åœ¨å·²ç»æˆåŠŸçˆ¬å–å½“å‰ url é—®è¯Šè®°å½•çš„å‰å‡ é¡µç„¶åå¼‚å¸¸ä¸­æ–­
                current_status_filename = 'CurrentStatus' + DATE_START + DATE_END + local_time
                current_status_content = advisory_date.strftime('%Y-%m-%d') + ' æ—¥ç¬¬ ' + str(date_page) + \
                                         ' é¡µé—®è¯Šåˆ—è¡¨å…±æœ‰ ' + str(len_item) + ' æ¡é—®è¯Šé¡µåœ°å€ï¼Œå·²æˆåŠŸæŠ“å– ' + str(i+1) + ' æ¡'
                with open(file_path + 'log/' + current_status_filename + '.txt', 'w', encoding=ENCODING_STYLE) \
                        as current_status:
                    current_status.write(current_status_content)
            # è®°å½•å«æœ‰ åŒ»æ‚£å¯¹è¯ title å’Œ urlçš„ date_page_url
            normal_date_page_url = 'NormalDatePageUrl' + DATE_START + DATE_END + local_time
            with open(file_path + 'log/' + normal_date_page_url + '.txt', 'a', encoding=ENCODING_STYLE) \
                    as normal_date_page:
                normal_date_page.write(date_page_url + '\n')
            time.sleep(TIME_SLEEP)
        except NoSuchElementException:
            # è®°å½•è¯¥æ—¥æ— è®°å½•ï¼ˆé¦–é¡µæ—  titleï¼Œurlï¼‰æˆ–è¯¥æ—¥æœ‰è®°å½•çš„æœ€åä¸€é¡µçš„åä¸€é¡µçš„ url
            print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), advisory_date.strftime('%Y-%m-%d'),
                  ' æ—¥åªæœ‰ ', str(date_page-1), ' é¡µé—®è¯Šåˆ—è¡¨ï¼Œå…¨éƒ¨æŠ“å–å®Œæ¯•')
            empty_date_page_url = 'EmptyDatePageUrl' + DATE_START + DATE_END + local_time
            with open(file_path + 'log/' + empty_date_page_url + '.txt', 'a', encoding=ENCODING_STYLE) \
                    as empty_date_page:
                empty_date_page.write(date_page_url + '\n')
            # é˜²æ­¢é¢‘ç¹è®¿é—®
            time.sleep(TIME_SLEEP)
            # é‡åˆ°æŸæ—¥æŸé¡µæ²¡æœ‰ title å’Œ urlï¼Œå³ç©ºç™½ï¼Œç»“æŸé¡µç å¾ªç¯ï¼Œç­‰å¾…å¼€å§‹ä¸‹ä¸€æ—¥
            break
        except TimeoutException:
            # è€ƒè™‘ IP è¢«å°
            print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()), date_page_url, ' åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè´¨é‡ï¼ŒIPï¼')
            # æ‰“å° date_page_url æ²¡æœ‰åŠ è½½æˆåŠŸçš„æƒ…å†µï¼Œè®°å½• url
            record_bug_date_page_url = 'BugDatePageUrl' + DATE_START + DATE_END + local_time
            with open(file_path + 'log/' + record_bug_date_page_url + '.txt', 'a', encoding=ENCODING_STYLE) \
                    as record_bug_date_page:
                record_bug_date_page.write(date_page_url + '\n')
            # ç»“æŸå¾ªç¯ï¼Œå¼€å§‹è¯·æ±‚ä¸‹ä¸€æ—¥çš„ç¬¬ä¸€é¡µ
            break


def creat_arr_title_url(item, len_item):
    """
    è§£æå‡ºå½“å‰é¡µä¸­çš„æ‰€æœ‰ title å’Œ urlï¼Œå¹¶å­˜å…¥äºŒç»´æ•°ç»„
    :param item:
    :param len_item:
    :return: arr_title_url
    """
    # æ•°ç»„åˆå§‹åŒ–ï¼Œè¡Œæ•°ä¸ºèŠ‚ç‚¹çš„ä¸ªæ•°ï¼Œj ä¸ºä¸´æ—¶å˜é‡
    arr_title_url = [[] for j in range(len_item)]
    for i in range(len_item):
        arr_title_url[i].append(item[i].get_attribute('href'))
        arr_title_url[i].append(item[i].text)
    return arr_title_url


def get_detail_page(detail_page_url, pre_file_name, file_path, local_time):
    """
    è·å–æŸä¸€é¡µä¸­æ‰€æœ‰ title å’Œ urlå¯¹åº”çš„åŒ»æ‚£å¯¹è¯è¯¦æƒ…é¡µï¼Œå¹¶ä¿å­˜åˆ°æœ¬åœ°
    :param detail_page_url:
    :param pre_file_name:
    :param file_path:
    :param local_time:
    :return:
    """
    try:
        # æ³¨æ„ href å€¼çš„'//'é—®é¢˜ï¼Œæš‚æœªå¤„ç†
        browser.get(detail_page_url)
        # ç­‰å¾…æ‰€æœ‰èŠ‚ç‚¹åŠ è½½å‡ºæ¥
        wait.until(EC.presence_of_all_elements_located)
        # ä¿å­˜ç½‘é¡µæºç ä¸º HTML æ–‡ä»¶åˆ°æœ¬åœ°ï¼Œæ³¨æ„ç¼–ç é—®é¢˜
        source_code = browser.page_source
        # HTML å‘½åå½¢å¦‚20180322_1_xxx.htm,ä»¥ä¸‹ç”¨åˆ‡ç‰‡çš„æ–¹æ³•è·å–æ²¡æœ‰'/'çš„éƒ¨åˆ†ï¼Œä¸ç„¶ä¼šè¢«è®¤ä¸ºæ˜¯è·¯å¾„
        # åˆ‡ç‰‡ä¹Ÿå¯ä»¥ç”¨ detail_page_url.split('/')[-1]
        # file_name = pre_file_name + detail_page_url.split('/')[-1]
        file_name = pre_file_name + detail_page_url[28:] + '.txt'
        # å‘½å è®°å½•æ‰€æœ‰æˆåŠŸä¿å­˜è‡³æœ¬åœ°çš„ç½‘é¡µçš„åç§° çš„æ–‡æœ¬
        record_filename_name = 'NameofSavedPages' + DATE_START + DATE_END + local_time
        # ä¿å­˜ç½‘é¡µæºç åˆ°æœ¬åœ°ï¼Œ file_name è‡ªå¸¦'.htm' åç¼€ï¼Œé‡‡ç”¨å’Œç½‘é¡µç›¸åŒçš„ gbk ç¼–ç 
        with open(file_path + file_name, 'w', encoding=ENCODING_STYLE) as file:
            file.write(source_code)
        # ä¿å­˜æˆåŠŸä¸‹è½½çš„ç½‘é¡µçš„åç§°åˆ°'NameofSavedPages'(æ ¹ç›®å½•)æ–‡ä»¶ä¸­ï¼Œè¿™é‡Œæš‚æ—¶ä¸åŠ å¯¹åº” title
        with open(file_path + 'log/' + record_filename_name + '.txt', 'a', encoding=ENCODING_STYLE) as record_filename:
            record_filename.write(file_name + '\n')
        # æŠ“å–æ¯ä¸ªé¡µé¢åç­‰å€™ä¸€ä¸‹ï¼Œé˜²æ­¢è¿‡å¿«è¢«å±è”½æˆ–å‡ºç° 5k æ–‡ä»¶
        time.sleep(TIME_SLEEP)
        # åˆ¤æ–­è¯¥é¡µæ˜¯å¦æœ‰åç»­é¡µï¼ˆç¿»é¡µï¼‰
        detail_pages_amount = re.search('<div class="mt50">.*?\D*?(\d+)\D*?é¡µ', source_code, re.S)
        if detail_pages_amount:
            for i in range(2, int(detail_pages_amount.group(1)) + 1):
                print('å½“å‰é—®è¯Šè®°å½•å…±æœ‰ ', detail_pages_amount.group(1), ' é¡µï¼Œ', 'æ­£åœ¨çˆ¬å–ç¬¬ ', str(i), ' é¡µï¼')
                detail_page_more_url = detail_page_url[:-4] + '_p_' + str(i) + '.htm'
                get_detail_page_more(detail_page_more_url, pre_file_name, file_path, local_time)
        # else:
        # print(detail_page_url, 'æ²¡æœ‰åç»­é¡µï¼')
    except Exception:
        print(detail_page_url, ' æœªæŠ“å–æˆåŠŸ!')
        # ä¸ºè®°å½•æ²¡æœ‰æˆåŠŸä¿å­˜çš„ HTML çš„ URL çš„ TXT æ–‡ä»¶å‘½å
        record_errfilename_name = 'NameofUnsavedPages' + DATE_START + DATE_END + local_time
        with open(file_path + 'log/' + record_errfilename_name + '.txt', 'a', encoding=ENCODING_STYLE) \
                as record_errfilename:
            record_errfilename.write(pre_file_name + '_' + detail_page_url + '\n')
        time.sleep(TIME_SLEEP)


def get_detail_page_more(detail_page_url, pre_file_name, file_path, local_time):
    """
    å¦‚æœæŸä¸ªå¯¹è¯æœ‰å¤šä¸ªé¡µé¢ï¼Œè¿™é‡Œè´Ÿè´£çˆ¬å–åç»­é¡µ
    :param detail_page_url:
    :param pre_file_name:
    :param file_path:
    :param local_time:
    :return:
    """
    try:
        browser.get(detail_page_url)
        wait.until(EC.presence_of_all_elements_located)
        source_code = browser.page_source
        file_name = pre_file_name + detail_page_url[28:] + '.txt'
        record_filename_name = 'NameofSavedPages' + DATE_START + DATE_END + local_time
        with open(file_path + file_name, 'w', encoding=ENCODING_STYLE) as file:
            file.write(source_code)
        with open(file_path + 'log/' + record_filename_name + '.txt', 'a', encoding=ENCODING_STYLE) as record_filename:
            record_filename.write(file_name + '\n')
        time.sleep(TIME_SLEEP)
    except Exception:
        print(detail_page_url, ' æœªæŠ“å–æˆåŠŸ!')
        record_errfilename_name = 'NameofUnsavedPages' + DATE_START + DATE_END + local_time
        with open(file_path + 'log/' + record_errfilename_name + '.txt', 'a', encoding=ENCODING_STYLE) \
                as record_errfilename:
            record_errfilename.write(pre_file_name + '_' + detail_page_url + '\n')
        time.sleep(TIME_SLEEP)


def make_dir():
    """
    ç”Ÿæˆä»¥ç½‘é¡µèµ·æ­¢æ—¶é—´å‘½åçš„æ–‡ä»¶å¤¹ï¼Œå¹¶è¿”å›è·¯å¾„ file_path
    :return: file_path
    """
    # å®šä¹‰å­˜å‚¨ HTML æ–‡ä»¶çš„è·¯å¾„ä¸ºåˆå§‹è·¯å¾„ä¸‹èµ·æ­¢æ—¶é—´å‘½åçš„æ–‡ä»¶å¤¹
    file_path = DIR_PATH + DATE_START + '_' + DATE_END + '/'
    # ç”Ÿæˆ TXT æ—¥å¿—å­˜å‚¨è·¯å¾„
    log_path = file_path + 'log/'
    exists = os.path.exists(log_path)
    if not exists:
        os.makedirs(log_path)
        # è¿”å›ä¸¤ä¸ªå‚æ•°éº»çƒ¦
        return file_path
    else:
        return file_path


def main():
    """
    ç”Ÿæˆfile_path å’Œlocal_time ä¾›æ•´ä¸ªç¨‹åºä½¿ç”¨
    :return:
    """
    # è€ƒè™‘ try ä¸€ä¸ªå¯¹å¸¸é‡çš„æ£€æŸ¥ï¼Œå¦‚ DATE_START ä¸€å®šåœ¨ DATE_ENG å‰é¢
    local_time = time.strftime('%Y%m%d_%H%M%S', time.localtime())
    # å¯ä»¥è€ƒè™‘ç»™æ–‡ä»¶å¤¹åç§°ä¹Ÿæ¥ä¸€ä¸ª local_time æ ‡è¯†
    # ========================================================
    # å½“å‰è·¯å¾„è®¾ç½®è¦æ±‚ï¼Œå¦‚æœç¨‹åºå› å¼‚å¸¸ç»ˆæ­¢ï¼Œéœ€è¦äººå·¥åˆ é™¤ç³»åˆ— log æ–‡ä»¶
    # ========================================================
    file_path = make_dir()
    try:
        # ä¸‹è½½åŒ»æ‚£å¯¹è¯çš„è¯¦æƒ…é¡µ
        down_detail_page(file_path, local_time)
        print('ğŸºğŸºğŸºğŸºğŸºğŸºğŸºğŸºğŸºğŸº  ä» ', DATE_START, ' åˆ° ', DATE_END, ' æœŸé—´çš„ç½‘é¡µå·²å…¨éƒ¨å­˜å…¥ ', file_path)
    except Exception:
        print('ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°ğŸ˜°  ä» ', DATE_START, ' åˆ° ', DATE_END, ' æœŸé—´çš„ç½‘é¡µè·å–å¤±è´¥!')
    browser.close()


if __name__ == '__main__':
    main()
